{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk.data\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [\"data/reviews_Home_and_Kitchen_5.json\"]\n",
    "filename = \"data/reviews_Home_and_Kitchen_5.json\"\n",
    "file_name = \"rawdata.pkl\"\n",
    "adversarial_file_name = \"adversialdata.pkl\"\n",
    "max_features = 20000\n",
    "maxlen = 100\n",
    "batch_size = 32\n",
    "num_class = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>489257</th>\n",
       "      <td>1</td>\n",
       "      <td>I use this set for both general food storage i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318868</th>\n",
       "      <td>0</td>\n",
       "      <td>Not a huge fan. I like to have a side for damp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527578</th>\n",
       "      <td>1</td>\n",
       "      <td>I have always wanted to have a French press at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102291</th>\n",
       "      <td>0</td>\n",
       "      <td>I purchased this to replace a breadmaker that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137178</th>\n",
       "      <td>0</td>\n",
       "      <td>I bought this pan because my 12\" pan needed to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233040</th>\n",
       "      <td>0</td>\n",
       "      <td>Just sayin'. I mean, honestly. Do we really ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413128</th>\n",
       "      <td>1</td>\n",
       "      <td>This rack fits the sink perfectly, and isn't b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149988</th>\n",
       "      <td>0</td>\n",
       "      <td>I bought one of the 20X72 inch mats for my wif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18029</th>\n",
       "      <td>1</td>\n",
       "      <td>I have four different sizes of these scoops an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129849</th>\n",
       "      <td>1</td>\n",
       "      <td>These replacement rubbers are perfect for use ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        overall                                         reviewText\n",
       "489257        1  I use this set for both general food storage i...\n",
       "318868        0  Not a huge fan. I like to have a side for damp...\n",
       "527578        1  I have always wanted to have a French press at...\n",
       "102291        0  I purchased this to replace a breadmaker that ...\n",
       "137178        0  I bought this pan because my 12\" pan needed to...\n",
       "233040        0  Just sayin'. I mean, honestly. Do we really ne...\n",
       "413128        1  This rack fits the sink perfectly, and isn't b...\n",
       "149988        0  I bought one of the 20X72 inch mats for my wif...\n",
       "18029         1  I have four different sizes of these scoops an...\n",
       "129849        1  These replacement rubbers are perfect for use ..."
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### edit datafram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "POS_TO_WORDNET = {\n",
    "    'NN': wn.NOUN\n",
    "#     'JJ': wn.ADJ,\n",
    "#     'JJR': wn.ADJ,\n",
    "#     'JJS': wn.ADJ,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alter_wordnet_antonyms(token):\n",
    "    if token[1] not in POS_TO_WORDNET: return None\n",
    "    w = token[0].lower()\n",
    "    wn_pos = POS_TO_WORDNET[token[1]]\n",
    "    synsets = wn.synsets(w, wn_pos)\n",
    "    if not synsets: return None\n",
    "    synset = synsets[0]\n",
    "    antonyms = []\n",
    "    for lem in synset.lemmas():\n",
    "        if lem.antonyms():\n",
    "            for a in lem.antonyms():\n",
    "                new_word = a.name()\n",
    "                if '_' in a.name(): continue\n",
    "                antonyms.append(new_word)\n",
    "    return antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = data['reviewText']\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 0\n",
    "for i, row in data.iterrows():\n",
    "    text = texts[i]\n",
    "    tokenized = tokenizer.tokenize(text)\n",
    "    words = word_tokenize(text)\n",
    "    tokens = nltk.pos_tag(words)\n",
    "    output = \"\"\n",
    "    for token in tokens:\n",
    "        if token == '.':\n",
    "            output = output + token\n",
    "            index = 0\n",
    "            break\n",
    "        if index != 0:\n",
    "            output = output + ' '\n",
    "        antonyms = alter_wordnet_antonyms(token)\n",
    "        if antonyms is None or len(antonyms) == 0:\n",
    "            output = output + token[0]\n",
    "        else:\n",
    "#             print(i, \": change from \", token[0], \" to \", antonyms[0])\n",
    "            output = output + antonyms[0]\n",
    "        index = index + 1\n",
    "    data.at[i,'reviewText'] = output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_pickle(adversarial_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Iusethissetforbothgeneralfoodstorageinthefridgeaswellastakinglunchestowork.Ifwestillwentonregularcampingtripsthese(alongwithothercontainersfromLunchBots)wouldbestapleitemsinmybackpackastheyareverylight,easytoclean,andleakproofwhichisgreatontreks.Forstoringleftovers,IlovethatIcanseethroughthelids--asaslazyasitsoundswetendtoforgetaboutleftoverswhenwecan'tseewhat'sinthecontainerandthenfoodtendstogetwasted.Thesekeepthatfromhappening.Forlunchesormealsonthego,theseareincrediblylightandtotallyleak-proof.Iusuallyusethedeeperoneforalargesaladandtheshallowonefordinnerleftoverstohavewiththesalad.Thelidssnapontightyetareeasytoopenandclose.Agreatadditiontoanyhousehold.\""
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reviewText'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 : \n",
      "I use this set for both general food storage in the fridge as well as taking lunches to work. If we still went on regular camping trips these (along with other containers from LunchBots) would be staple items in my backpack as they are very light, easy to clean, and leakproof which is great on treks.For storing leftovers, I love that I can see through the lids -- as as lazy as it sounds we tend to forget about leftovers when we can't see what's in the container and then food tends to get wasted. These keep that from happening.For lunches or meals on the go, these are incredibly light and totally leak-proof. I usually use the deeper one for a large salad and the shallow one for dinner leftovers to have with the salad.The lids snap on tight yet are easy to open and close.A great addition to any household.\n",
      "\n",
      "1 : \n",
      "Not a huge fan. I like to have a side for damp clothes (towels and such after shower) and dry on the other. That would of been great had it not got moldy on the bottom after a few days.\n",
      "\n",
      "2 : \n",
      "I have always wanted to have a French press at home and got a great deal on this one to try it out. I highly recommend this as a starter, but may invest in a heavier model down the road.\n",
      "\n",
      "3 : \n",
      "I purchased this to replace a breadmaker that was getting old. I am very disappointed! On the LIGHT setting, the bread is overdone - with a very dark and hard crust. It does not mix the ingredients well, as there are bits of dough and loose particles of ingredients along the outside of the loaf. I would not recommend this item to anyone. I will not be buying any more Sunbeam breadmakers. Big mistake. I miss my old breadmaker, and will be looking for another one. This one is going to Goodwill (so be careful what you buy there!).\n",
      "\n",
      "4 : \n",
      "I bought this pan because my 12\" pan needed to be replaced and in hopes that it would be as good and match my Faber-ware and Food Network stainless steel pans; I am disappointed. The pan is only washed by hand and heat setting is med to med-hi, how ever the pan is showing black pitting spots on the lid and pan. The pan is not made with quality stainless steel to show tarnishing in only a few weeks and four times being used. I have owned my Faber-ware for more than 8 years and it is still in great shape and it was washed in the dishwasher a few times. I won't buy this product again, it is not a good quality pan. I am very disappointed.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(i, \": \")\n",
    "    print(texts.iloc[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" I use this set for both general food storage in the fridge as well as taking lunches to work . If we still went on regular camping trips these ( along with other containers from LunchBots ) would be staple items in my backpack as they are very light , easy to clean , and leakproof which is great on treks.For storing leftovers , I love that I can see through the lids -- as as lazy as it sounds we tend to forget about leftovers when we ca n't see what 's in the container and then food tends to get wasted . These keep that from happening.For lunches or meals on the go , these are incredibly light and totally leak-proof . I usually use the deeper one for a large salad and the shallow one for dinner leftovers to have with the salad.The lids snap on tight yet are easy to open and close.A great addition to any household .\""
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('dog.n.01'),\n",
       " Synset('frump.n.01'),\n",
       " Synset('dog.n.03'),\n",
       " Synset('cad.n.01'),\n",
       " Synset('frank.n.02'),\n",
       " Synset('pawl.n.01'),\n",
       " Synset('andiron.n.01'),\n",
       " Synset('chase.v.01')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog') # doctest: +ELLIPSIS +NORMALIZE_WHITESPACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Synset('chase.v.01')]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synsets('dog', pos=wn.VERB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('dog.n.01')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('dog.n.01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a member of the genus Canis (probably descended from the common wolf) that has been domesticated by man since prehistoric times; occurs in many breeds\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('dog.n.01').definition())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wn.synset('dog.n.01').examples())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the dog barked all night\n"
     ]
    }
   ],
   "source": [
    "print(wn.synset('dog.n.01').examples()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('dog.n.01.dog'),\n",
       " Lemma('dog.n.01.domestic_dog'),\n",
       " Lemma('dog.n.01.Canis_familiaris')]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('dog.n.01').lemmas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dog', 'domestic_dog', 'Canis_familiaris']"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(lemma.name()) for lemma in wn.synset('dog.n.01').lemmas()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('dog.n.01')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.lemma('dog.n.01.dog').synset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\vwslz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
